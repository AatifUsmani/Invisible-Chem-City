{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Scoring Model — Invisible City\n",
    "\n",
    "**Goal**: Assign each facility a risk score based on how much they release, what they release, how often, and where.\n",
    "\n",
    "- Feature engineering: total emissions, frequency, toxicity proxy\n",
    "- Normalize features, combine into single score\n",
    "- Optional: fit regression to learn weights\n",
    "- Plot risk score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "BASE = os.getcwd()\n",
    "PROC = os.path.join(BASE, 'data', 'processed')\n",
    "OUT = os.path.join(BASE, 'output')\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT, 'figures'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load cleaned data and releases (for toxicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facilities = pd.read_csv(os.path.join(PROC, 'facilities_clean.csv'))\n",
    "releases = pd.read_csv(os.path.join(PROC, 'releases_clean.csv'))\n",
    "\n",
    "# Simple toxicity proxy (1-10) per chemical (match cleaned chemical_name)\n",
    "TOXICITY = {\n",
    "    'Ammonia': 4, 'Benzene': 9, 'Lead': 10, 'Sulphuric Acid': 6, 'Toluene': 5,\n",
    "    'Xylene': 5, 'Zinc': 4, 'Particulate Matter': 6, 'Vocs': 5, 'Nitrogen Oxides': 5\n",
    "}\n",
    "releases['toxicity'] = releases['chemical_name'].map(TOXICITY).fillna(5)\n",
    "tox_by_facility = releases.groupby('facility_id').agg(\n",
    "    mean_toxicity=('toxicity', 'mean'),\n",
    "    max_toxicity=('toxicity', 'max')\n",
    ").reset_index()\n",
    "facilities = facilities.merge(tox_by_facility, on='facility_id', how='left')\n",
    "facilities['mean_toxicity'] = facilities['mean_toxicity'].fillna(5)\n",
    "facilities['max_toxicity'] = facilities['max_toxicity'].fillna(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = facilities.copy()\n",
    "df['log_release'] = np.log1p(df['total_release_kg'])\n",
    "df['release_frequency'] = df['release_count']\n",
    "df['toxicity_proxy'] = df['mean_toxicity'] * 0.5 + df['max_toxicity'] * 0.5\n",
    "\n",
    "features = ['log_release', 'release_frequency', 'toxicity_proxy']\n",
    "X = df[features].copy()\n",
    "X['release_frequency'] = np.log1p(X['release_frequency'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=features, index=df.index)\n",
    "df[features] = X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Risk score: weighted sum (interpretable)\n",
    "\n",
    "Risk ≈ amount × toxicity × frequency. We use normalized features and weights: 0.5 amount, 0.3 toxicity, 0.2 frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {'log_release': 0.5, 'toxicity_proxy': 0.3, 'release_frequency': 0.2}\n",
    "df['risk_score'] = sum(df[k] * w for k, w in weights.items())\n",
    "df['risk_score'] = (df['risk_score'] - df['risk_score'].min()) / (df['risk_score'].max() - df['risk_score'].min() + 1e-9) * 100\n",
    "df['risk_score'] = df['risk_score'].round(2)\n",
    "\n",
    "df.to_csv(os.path.join(PROC, 'facilities_with_risk.csv'), index=False)\n",
    "print('Risk score range:', df['risk_score'].min(), '-', df['risk_score'].max())\n",
    "display(df[['facility_id', 'industry', 'total_release_kg', 'risk_score']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Distribution of risk scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.hist(df['risk_score'], bins=30, color='steelblue', edgecolor='white', alpha=0.8)\n",
    "ax.axvline(df['risk_score'].quantile(0.95), color='coral', linestyle='--', label='Top 5%')\n",
    "ax.set_xlabel('Risk score')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Distribution of facility risk scores')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT, 'figures', 'risk_distribution.png'), dpi=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
